from datetime import datetimeimport errnoimport osimport matplotlib.pyplot as pltimport timeitimport pymysqlfrom shse.mlearn.neural_network import DNNimport torchfrom shse.mlearn.utils import save_model, load_modelfrom sklearn.externals import joblibfrom sklearn.model_selection import train_test_splitimport numpy as npfrom sklearn.metrics import confusion_matrixfrom sklearn.preprocessing import StandardScalerdef get_Ratio(sensorValue):    sensorValue = np.array(sensorValue)    featlist = []    for i in range(6):        for j in range(6):            if i != j :                featlist.append(sensorValue[:, j] / sensorValue[:, i])    return np.transpose(featlist)def modelTrain(x_data,y_data):    # now = datetime.utcnow().strftime("%Y%m%d")    # model_dir = "model/{}/".format(now)    model_dir = "Model/Classify/"+load_date    name = model_dir + "/Clf_" + data_type    try:        if not (os.path.isdir(model_dir)):            os.makedirs(os.path.join(model_dir))    except OSError as e:        if e.errno != errno.EEXIST:            raise    start = timeit.default_timer()    before = 0    if is_ratio:        scaler = StandardScaler()        scaler.fit(x_data)        x_data = scaler.transform(x_data)        joblib.dump(scaler, model_dir+"/"+data_type+"_scaler.pkl")    x_data = torch.Tensor(x_data).float()    y_data = torch.Tensor(y_data).long()    input = len(x_data[0])    hidden = 20    hidden2 = 30    hidden3 = 30    hidden4 = 50    hidden5 = 40    output = 10    epoch = 20000    learning_rate = 0.001    batch_size = 10    dnn = DNN(input, output, [hidden,hidden2,hidden3,hidden4,hidden5])    for step, loss in dnn.learn(x_data, y_data, epoch=epoch, learning_rate=learning_rate, batch_size=batch_size):        if step % 100 == 0:            gap = loss.tolist() - before            before = loss.tolist()            pick = timeit.default_timer()            time_gap = pick-start            print('step : %d, loss : %.10f, loss gap = %.10f, seconds = %d' %(step,loss.tolist(),gap,time_gap))        if loss == 0:            gap = loss.tolist() - before            pick = timeit.default_timer()            time_gap = pick - start            break    print('step : %d, loss : %.10f, loss gap = %.10f, seconds = %d' % (step, loss.tolist(), gap, time_gap))    save_model(dnn, name+'.pkl')def modelValid(x_data,y_data):    pred=[]    count=0    model_dir = "Model/Classify/"+load_date    name = model_dir + '/Clf_' + data_type    if is_ratio:        scaler = joblib.load(model_dir+"/"+data_type+"_scaler.pkl")        x_data = scaler.transform(x_data)    dnn = load_model(name+'.pkl')    dnn.train(False)    for i in range(len(x_data)):        x = torch.Tensor(x_data[i]).float()        x = x.unsqueeze(dim=0)        result = dnn.forward(x.cuda())        result_label = torch.argmax(result, dim=-1)        result_label = result_label.squeeze().tolist()        if result_label==y_data[i]:            count=count+1        pred.append(result_label)        print(result_label, "-", y_data[i])    percent = (count/len(x_data))*100    print(str(percent)+"%")    model_dir = model_dir + "/cm/"    try:        if not (os.path.isdir(model_dir)):            os.makedirs(os.path.join(model_dir))    except OSError as e:        if e.errno != errno.EEXIST:            raise    name = model_dir+data_type+"_cm.png"    norm_name = model_dir+data_type+"_norm_cm.png"    plot_confusion_matrix(np.asarray(y_data),np.asarray(pred), normalize=False,path=name,percent=percent)    plot_confusion_matrix(np.asarray(y_data), np.asarray(pred), normalize=True,path=norm_name,percent=percent)def plot_confusion_matrix(y_true, y_pred,                          normalize=False,                          title=None,                          cmap=plt.cm.Blues,                          path=False,                          percent=100):    """    This function prints and plots the confusion matrix.    Normalization can be applied by setting `normalize=True`.    """    if not title:        if normalize:            title = 'Normalized confusion matrix : ' + str(percent) + '%'        else:            title = 'Confusion matrix, without normalization : ' + str(percent) +'%'    # Compute confusion matrix    cm = confusion_matrix(y_true, y_pred)    # Only use the labels that appear in the data    # classes = unique_labels(y_true, y_pred)    classes = ['h2s+nh3','h2s+ch3sh','h2s+co','h2s+ch4','nh3+ch3sh','nh3+co','nh3+ch4','ch3sh+co','ch3sh+ch4','co+ch4']    if normalize:        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]    fig, ax = plt.subplots()    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)    ax.figure.colorbar(im, ax=ax)    # We want to show all ticks...    ax.set(xticks=np.arange(cm.shape[1]),           yticks=np.arange(cm.shape[0]),           # ... and label them with the respective list entries           xticklabels=classes, yticklabels=classes,           title=title,           ylabel='True label',           xlabel='Predicted label')    # Rotate the tick labels and set their alignment.    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",             rotation_mode="anchor")    # Loop over data dimensions and create text annotations.    fmt = '.2f' if normalize else 'd'    thresh = cm.max() / 2.    for i in range(cm.shape[0]):        for j in range(cm.shape[1]):            ax.text(j, i, format(cm[i, j], fmt),                    ha="center", va="center",                    color="white" if cm[i, j] > thresh else "black")    fig.tight_layout()    plt.savefig(path)    return axdef Db_seelct(start,end):    # print('Data_number select')    conn = pymysql.connect(host='203.250.78.169',port=3307, database='gas', user='root', password='offset01')    with conn.cursor() as cursor:        sql = 'SELECT `H2`,  `VOC`,  `Methyl`,  `LP`,  `Solvent`,  `NH3` FROM `gas`.`gas_log` ' \              'WHERE '+str(start)+'<=`idx` AND `idx`<='+str(end)+';'        cursor.execute(sql)        data = cursor.fetchall()    conn.close()    return dataif __name__ == '__main__':    data_type = 'mix'    is_ratio = True    print(data_type, is_ratio)    save_date = '20191212'    load_date = '20191212'    classes = []    features = []    start = []    end = []    class_num = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]    # Class 0    # normal_start = [63000, 36980, 38300, 64479, 65600, 616836]    # normal_end = [63100, 37080, 38400, 64579, 65700, 618470]    # start.append(normal_start)    # end.append(normal_end)    # Class 0    h2s_nh3_start = [607605, 607976, 618807]    h2s_nh3_end = [607725, 608092, 618906]    start.append(h2s_nh3_start)    end.append(h2s_nh3_end)    # Class 1    h2s_ch3sh_start = [608395, 608647, 619098]    h2s_ch3sh_end = [608507, 608749, 619199]    start.append(h2s_ch3sh_start)    end.append(h2s_ch3sh_end)    # Class 2    h2s_co_start = [608893, 609801, 609107, 610052, 619345]    h2s_co_end = [608943, 609908, 609142, 610171, 619406]    start.append(h2s_co_start)    end.append(h2s_co_end)    # Class 3    h2s_ch4_start = [609282, 609540, 619635]    h2s_ch4_end = [609400, 609659, 619710]    start.append(h2s_ch4_start)    end.append(h2s_ch4_end)    # Class 4    nh3_ch3sh_start = [610924, 611151, 620127]    nh3_ch3sh_end = [611000, 611227, 620238]    start.append(nh3_ch3sh_start)    end.append(nh3_ch3sh_end)    # Class 5    nh3_co_start = [610418, 610669, 620419]    nh3_co_end = [610523, 610783, 620527]    start.append(nh3_co_start)    end.append(nh3_co_end)    # Class 6    nh3_ch4_start = [611377, 611627, 619870]    nh3_ch4_end = [611482, 611745, 619977]    start.append(nh3_ch4_start)    end.append(nh3_ch4_end)    # Class 7    ch3sh_co_start = [611326, 612539, 620657]    ch3sh_co_end = [611402, 612650, 620728]    start.append(ch3sh_co_start)    end.append(ch3sh_co_end)    # Class 8    ch3sh_ch4_start = [611883, 612103, 620883]    ch3sh_ch4_end = [611959, 612179, 620983]    start.append(ch3sh_ch4_start)    end.append(ch3sh_ch4_end)    # Class 9    co_ch4_start = [612799, 613027, 621122]    co_ch4_end = [612876, 613136, 621232]    start.append(co_ch4_start)    end.append(co_ch4_end)    for i in range(len(start)):        start_tmp = start[i]        end_tmp = end[i]        for j in range(len(start_tmp)):            tmp_data = Db_seelct(start_tmp[j], end_tmp[j])            if j == 0:                data = tmp_data            else:                data = np.vstack((data, tmp_data))            for k in range(len(tmp_data)):                classes.append(class_num[i])        if i == 0:            features = data        else:            features = np.vstack((features, data))    if is_ratio:        features = get_Ratio(features)    x_train, x_valid, y_train, y_valid = train_test_split(features, classes, test_size=0.3, random_state=321)    modelTrain(x_train, y_train)    modelValid(x_valid, y_valid)#-------------------------------------------------------------    classes = []    features = []    start = []    end = []    h2s_nh3_start = [618807]    h2s_nh3_end = [618906]    start.append(h2s_nh3_start)    end.append(h2s_nh3_end)    # Class 1    h2s_ch3sh_start = [619098]    h2s_ch3sh_end = [619199]    start.append(h2s_ch3sh_start)    end.append(h2s_ch3sh_end)    # Class 2    h2s_co_start = [619345]    h2s_co_end = [619406]    start.append(h2s_co_start)    end.append(h2s_co_end)    # Class 3    h2s_ch4_start = [619635]    h2s_ch4_end = [619710]    start.append(h2s_ch4_start)    end.append(h2s_ch4_end)    # Class 4    nh3_ch3sh_start = [620127]    nh3_ch3sh_end = [620238]    start.append(nh3_ch3sh_start)    end.append(nh3_ch3sh_end)    # Class 5    nh3_co_start = [620419]    nh3_co_end = [620527]    start.append(nh3_co_start)    end.append(nh3_co_end)    # Class 6    nh3_ch4_start = [619870]    nh3_ch4_end = [619977]    start.append(nh3_ch4_start)    end.append(nh3_ch4_end)    # Class 7    ch3sh_co_start = [620657]    ch3sh_co_end = [620728]    start.append(ch3sh_co_start)    end.append(ch3sh_co_end)    # Class 8    ch3sh_ch4_start = [620883]    ch3sh_ch4_end = [620983]    start.append(ch3sh_ch4_start)    end.append(ch3sh_ch4_end)    # Class 9    co_ch4_start = [621122]    co_ch4_end = [621232]    start.append(co_ch4_start)    end.append(co_ch4_end)    for i in range(len(start)):        start_tmp = start[i]        end_tmp = end[i]        for j in range(len(start_tmp)):            tmp_data = Db_seelct(start_tmp[j], end_tmp[j])            if j == 0:                data = tmp_data            else:                data = np.vstack((data, tmp_data))            for k in range(len(tmp_data)):                classes.append(class_num[i])        if i == 0:            features = data        else:            features = np.vstack((features, data))    classes = np.array(classes)    if is_ratio:        features = get_Ratio(features)    features = np.vstack((features, x_valid))    classes = np.hstack((classes, y_valid))    modelValid(features, classes)